{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bbcc5b4",
   "metadata": {},
   "source": [
    "# Bayesian inference with priors: from parallax to distance\n",
    "\n",
    "In this tutorial, we will explore how astronomers use parallax to measure distances to stars and apply Bayesian inference to improve distance estimates when there is uncertainty in the measurements. We'll introduce log-likelihoods, log-priors, and log-posteriors, and show how these concepts can help us account for uncertainties and apply different beliefs (priors) about the star's distance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1415da",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#1.-What-is-Parallax?\" data-toc-modified-id=\"1.-What-is-Parallax?-0.1\">1. <strong>What is Parallax?</strong></a></span></li><li><span><a href=\"#2.-Dealing-with-Uncertainty\" data-toc-modified-id=\"2.-Dealing-with-Uncertainty-0.2\">2. <strong>Dealing with Uncertainty</strong></a></span></li><li><span><a href=\"#3.-Bayesian-Inference:-Likelihood,-Priors,-and-Posteriors\" data-toc-modified-id=\"3.-Bayesian-Inference:-Likelihood,-Priors,-and-Posteriors-0.3\">3. <strong>Bayesian Inference: Likelihood, Priors, and Posteriors</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#a.-Likelihood:\" data-toc-modified-id=\"a.-Likelihood:-0.3.1\">a. <strong>Likelihood</strong>:</a></span></li><li><span><a href=\"#b.-Priors:\" data-toc-modified-id=\"b.-Priors:-0.3.2\">b. <strong>Priors</strong>:</a></span></li><li><span><a href=\"#c.-Posterior:\" data-toc-modified-id=\"c.-Posterior:-0.3.3\">c. <strong>Posterior</strong>:</a></span></li><li><span><a href=\"#b.-Why-logarithmic-forms?\" data-toc-modified-id=\"b.-Why-logarithmic-forms?-0.3.4\">b. <strong>Why logarithmic forms?</strong></a></span></li></ul></li><li><span><a href=\"#4.-Implementing-the-Parallax-Model-in-Python\" data-toc-modified-id=\"4.-Implementing-the-Parallax-Model-in-Python-0.4\">4. <strong>Implementing the Parallax Model in Python</strong></a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-the-Log-Likelihood,-Log-Prior,-and-Log-Posterior\" data-toc-modified-id=\"Define-the-Log-Likelihood,-Log-Prior,-and-Log-Posterior-0.4.1\">Define the Log-Likelihood, Log-Prior, and Log-Posterior</a></span></li><li><span><a href=\"#Create-some-example-case\" data-toc-modified-id=\"Create-some-example-case-0.4.2\">Create some example case</a></span></li><li><span><a href=\"#Calculate-logarithmic-and-linear-likelihood,-prior,-and-posterior\" data-toc-modified-id=\"Calculate-logarithmic-and-linear-likelihood,-prior,-and-posterior-0.4.3\">Calculate logarithmic and linear likelihood, prior, and posterior</a></span></li></ul></li></ul></li><li><span><a href=\"#5.--Different-prior\" data-toc-modified-id=\"5.--Different-prior-1\">5.  Different prior</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139da3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import patches\n",
    "\n",
    "# Make the size and fonts larger for this presentation\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['lines.linewidth'] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219e37f",
   "metadata": {},
   "source": [
    "### 1. **What is Parallax?**\n",
    "\n",
    "Parallax is the apparent shift in the position of an object when observed from different positions. In astronomy, we measure the angle by which a star seems to shift when viewed from different points in Earth's orbit. This shift, known as the **parallax angle**, allows us to calculate the distance to a star.\n",
    "\n",
    "- **Parallax Angle (`parallax`)**: The angular shift measured in arcseconds.\n",
    "- **Distance (`distance`)**: The distance to the star, calculated as:\n",
    "\n",
    "$$\n",
    "D_\\varpi = distance = \\frac{1}{parallax} \\cdot \\frac{1\\,\\mathrm{pc}}{1\\,\\mathrm{arcsec}} = \\frac{1}{\\varpi}  \\cdot \\frac{1\\,\\mathrm{pc}}{1\\,\\mathrm{arcsec}}\n",
    "$$\n",
    "\n",
    "If the parallax angle of a star is 0.1 arcseconds, the distance to the star is:\n",
    "\n",
    "$$\n",
    "D_\\varpi = \\frac{1}{0.1\\,\\mathrm{arcsec}} \\cdot \\frac{1\\,\\mathrm{pc}}{1\\,\\mathrm{arcsec}} = 10 \\text{ parsecs}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e353d29",
   "metadata": {},
   "source": [
    "### 2. **Dealing with Uncertainty**\n",
    "\n",
    "Real measurements are never perfect. There's always uncertainty in the measured parallax angle, which introduces uncertainty into the distance calculation. Instead of a single value for the distance, we infer a **range of possible distances** based on the observed parallax and the uncertainty (standard deviation).\n",
    "\n",
    "- **Uncertainty in `parallax`**: Parallax measurements come with a standard deviation, `sigma_parallax`, which represents the measurement error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f775293e",
   "metadata": {},
   "source": [
    "### 3. **Bayesian Inference: Likelihood, Priors, and Posteriors**\n",
    "\n",
    "Bayesian inference is a statistical approach that allows us to incorporate prior knowledge about a parameter (in this case, the star’s distance) along with the observed data (parallax measurement). The goal is to compute the **posterior distribution**, which combines the likelihood of the observed data with the prior beliefs.\n",
    "\n",
    "#### a. **Likelihood**:\n",
    "The likelihood represents the probability of observing the data (`parallax`, parallax measurement $\\varpi$) given a true distance $D_\\varpi$ (`distance`). For parallax measurements, we assume a normal distribution for the likelihood:\n",
    "\n",
    "$$\n",
    "\\text{Likelihood: } P(\\varpi | D_\\varpi) \\sim \\mathcal{N} \\left(\\frac{1}{D_\\varpi}, \\sigma_\\varpi \\right)\n",
    "$$\n",
    "\n",
    "The **log-likelihood** is often more convenient to work with, especially when combining many terms. The log-likelihood for a normal distribution is:\n",
    "\n",
    "$$\n",
    "\\ln P(\\varpi | D_\\varpi) = -\\frac{1}{2} \\frac{(\\varpi - \\frac{1}{D_\\varpi})^2}{\\sigma_\\varpi^2} - \\frac{1}{2} \\ln(2 \\pi \\sigma_\\varpi^2)\n",
    "$$\n",
    "\n",
    "#### b. **Priors**:\n",
    "A prior reflects our belief about the distribution of `distance` before taking into account the data. We may have different priors:\n",
    "- **Uniform Prior**: We assume the star is equally likely to be at any distance up to some maximum distance, `distance_max` $D_\\text{max}$.\n",
    "\n",
    "$$\n",
    "P(D_\\varpi) = \\frac{1}{D_{\\text{max}}}, \\quad \\text{for } 0 < D_\\varpi < D_{\\text{max}}\n",
    "$$\n",
    "\n",
    "- **Log-Prior**:\n",
    "$$\n",
    "\\ln P(D_\\varpi) = \\ln \\left( \\frac{1}{D_\\text{max}} \\right), \\quad \\text{for } 0 < D_\\varpi < D_{\\text{max}}\n",
    "$$\n",
    "\n",
    "#### c. **Posterior**:\n",
    "The posterior combines the likelihood and prior to provide a new distribution, giving the probability of the true distance (`distance`) given the parallax measurement (`parallax`):\n",
    "\n",
    "$$\n",
    "\\text{Posterior: } P(D_\\varpi | \\varpi) \\propto P(\\varpi | D_\\varpi) \\cdot P(D_\\varpi)\n",
    "$$\n",
    "\n",
    "And in log form:\n",
    "$$\n",
    "\\ln P(D_\\varpi | \\varpi) = \\ln P(\\varpi | D_\\varpi) + \\ln P(D_\\varpi)\n",
    "$$\n",
    "\n",
    "#### b. **Why logarithmic forms?**\n",
    "\n",
    "- **Preventing Underflow (Handling Very Small Numbers):** When dealing with probabilities, especially in large datasets, the values of the likelihood and posterior probabilities can become very small (close to zero).  \n",
    "- **Simplifying Multiplications:** Addition is computationally easier and more efficient than multiplication, especially when dealing with many data points or large datasets.  \n",
    "- **Numerical Stability:** When working with very small or very large numbers (which are common in likelihood and posterior calculations), rounding errors can accumulate, leading to inaccuracies.  \n",
    "- **Better Optimization:** Gradient-based optimization algorithms (like those used in machine learning and statistics) often perform better with sums (logarithmic values) rather than products, which can lead to more efficient and stable convergence.  \n",
    "- **Logarithms are easier to work with in Probabilistic Modeling:** In many probabilistic models, particularly those that involve normal distributions or other exponential family distributions, the log-likelihood often takes a very convenient form. For instance, the log-likelihood of a normal distribution is quadratic in the parameters, which is easier to work with mathematically:\n",
    "$$\n",
    "\\ln P(x | \\mu, \\sigma) = - \\frac{(x - \\mu)^2}{2\\sigma^2} - \\frac{1}{2} \\ln(2 \\pi \\sigma^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda0bebf",
   "metadata": {},
   "source": [
    "### 4. **Implementing the Parallax Model in Python**\n",
    "\n",
    "We'll now implement this step-by-step in Python using `matplotlib` and `scipy.stats` for the likelihood and prior functions, but this time focusing on **log-likelihoods** and **log-priors**.\n",
    "\n",
    "#### Define the Log-Likelihood, Log-Prior, and Log-Posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801bc711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Log-Likelihood function for parallax measurement\n",
    "def log_likelihood(parallax, distance, sigma_parallax):\n",
    "    \"\"\"Log-likelihood for parallax measurement.\n",
    "    \n",
    "    Parameters:\n",
    "    parallax : parallax value\n",
    "    distance : true distance\n",
    "    sigma_parallax : standard deviation of parallax error\n",
    "    \n",
    "    Returns:\n",
    "    Log-likelihood of observing w given r and wsd.\n",
    "    \"\"\"\n",
    "    return -0.5 * ((parallax - 1/distance)**2 / sigma_parallax**2) - np.log(sigma_parallax * np.sqrt(2 * np.pi))\n",
    "\n",
    "# Log-Prior function (uniform between 0 and rmax)\n",
    "def log_prior(distance, distance_max):\n",
    "    \"\"\"Log-uniform prior for distance (r) truncated between 0 and rmax.\"\"\"\n",
    "    if distance > 0 and distance < distance_max:\n",
    "        return -np.log(distance_max)\n",
    "    else:\n",
    "        return -np.inf  # log(0) for impossible distances\n",
    "    \n",
    "# Log-Posterior function\n",
    "def log_posterior(parallax, distance, sigma_parallax, distance_max):\n",
    "    \"\"\"Log-posterior for parallax measurement combining likelihood and prior.\"\"\"\n",
    "    return log_likelihood(parallax, distance, sigma_parallax) + log_prior(distance, distance_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294bdf51",
   "metadata": {},
   "source": [
    "#### Create some example case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6144706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parallax measurement and uncertainty\n",
    "parallax = 0.5          # Parallax measurement\n",
    "sigma_parallax = 0.1    # Parallax uncertainty (standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5ea028",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Generate random parallax values based on the measurement and uncertainty (assumed Gaussian)\n",
    "n_samples = 10000  # Number of samples to simulate\n",
    "parallax_samples = np.random.normal(parallax, sigma_parallax, n_samples)\n",
    "\n",
    "# Calculate distance as 1/parallax, but filter out cases where the parallax is negative\n",
    "distance_samples = 1 / parallax_samples\n",
    "\n",
    "distance_percentiles = np.percentile(distance_samples, q=[16,50,84])\n",
    "\n",
    "# Count how many distances are negative\n",
    "negative_distances = np.sum(parallax_samples <= 0)\n",
    "\n",
    "# Calculate the percentage of negative distances\n",
    "negative_distance_percentage = (negative_distances / n_samples) * 100\n",
    "\n",
    "# Create a 2-panel plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "# Panel a: Distribution of parallax values\n",
    "axes[0].hist(parallax_samples, bins=50, histtype='step', lw=2)\n",
    "axes[0].axvline(np.mean(parallax_samples), color='k', linestyle='--', label = 'Mean')\n",
    "axes[0].set_title(r'$\\varpi$ = '+f'{parallax} ± {sigma_parallax} arcsec')\n",
    "axes[0].set_xlabel('Parallax (arcseconds)', fontsize=14)\n",
    "axes[0].set_ylabel('Nr. / '+str(n_samples), fontsize=14)\n",
    "axes[0].legend(loc='upper right')\n",
    "\n",
    "# # Panel b: Distribution of 1/parallax (distances)\n",
    "axes[1].hist(distance_samples, bins=50, histtype='step',lw=2)\n",
    "\n",
    "axes[1].set_title(r'$1 / \\varpi = '+str(np.round(distance_percentiles[1],2))+'_{-'+str(np.round(distance_percentiles[1]-distance_percentiles[0],2))+'}^{+'+str(np.round(distance_percentiles[2]-distance_percentiles[1],2))+r'}\\,\\mathrm{pc}$')\n",
    "axes[1].axvline(distance_percentiles[1], color='k', linestyle='--', label = 'Median')\n",
    "axes[1].legend(loc='upper right')\n",
    "axes[1].set_xlabel('Distance (1/parallax)', fontsize=14)\n",
    "axes[0].set_ylabel('Nr. / '+str(n_samples), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cf843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example parallax measurement and uncertainty\n",
    "parallax = 0.02  # True parallax -> distance = 50 pc\n",
    "sigma_parallax = 0.04    # Parallax uncertainty (standard deviation)\n",
    "\n",
    "# Range of distances\n",
    "distance_vals = np.linspace(0.1, 500, 1000)\n",
    "\n",
    "# Compute uniform log-prior (assume max distance is 20 parsecs)\n",
    "distance_max = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf288ee",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Generate random parallax values based on the measurement and uncertainty (assumed Gaussian)\n",
    "n_samples = 10000  # Number of samples to simulate\n",
    "parallax_samples = np.random.normal(parallax, sigma_parallax, n_samples)\n",
    "\n",
    "# Calculate distance as 1/parallax, but filter out cases where the parallax is negative\n",
    "distance_samples = 1 / parallax_samples\n",
    "\n",
    "# Count how many distances are negative\n",
    "negative_distances = np.sum(parallax_samples <= 0)\n",
    "\n",
    "# Calculate the percentage of negative distances\n",
    "negative_distance_percentage = (negative_distances / n_samples) * 100\n",
    "\n",
    "# Create a 2-panel plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "# Panel a: Distribution of parallax values\n",
    "axes[0].hist(parallax_samples, bins=np.linspace(parallax - 3*sigma_parallax,parallax + 3*sigma_parallax,25), histtype='step', lw=2)\n",
    "axes[0].hist(parallax_samples[parallax_samples < 0], bins=np.linspace(parallax - 3*sigma_parallax,parallax + 3*sigma_parallax,25), color = 'C3', lw=2, label = r'$\\varpi < 0\\,\\mathrm{arcsec}$')\n",
    "axes[0].axvline(parallax, color='k', linestyle='--', label = 'Mean')\n",
    "axes[0].set_title(r'$\\varpi$ = '+f'{parallax} ± {sigma_parallax} arcsec')\n",
    "axes[0].set_xlabel('Parallax (arcseconds)', fontsize=14)\n",
    "axes[0].set_ylabel('Nr. / '+str(n_samples), fontsize=14)\n",
    "axes[0].legend(loc='upper right', fontsize=12)\n",
    "\n",
    "# # Panel b: Distribution of 1/parallax (distances)\n",
    "axes[1].hist(distance_samples, bins=np.linspace(-200,distance_max,50), histtype='step',lw=2)\n",
    "axes[1].hist(distance_samples[distance_samples < 0], bins=np.linspace(-200,distance_max,50), color = 'C1', label = 'Physically\\nimpossible')\n",
    "axes[1].set_title(r'$1 / \\varpi$ = '+f'{1/parallax} ± ?? pc')\n",
    "axes[1].legend(loc='upper right', fontsize=12)\n",
    "axes[1].set_xlabel('Distance (1/parallax)', fontsize=14)\n",
    "axes[0].set_ylabel('Nr. / '+str(n_samples), fontsize=14)\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d776221",
   "metadata": {},
   "source": [
    "#### Calculate logarithmic and linear likelihood, prior, and posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelihood_vals = [log_likelihood(parallax, distance, sigma_parallax) for distance in distance_vals]\n",
    "log_prior_vals = [log_prior(distance, distance_max) for distance in distance_vals]\n",
    "log_posterior_vals = [log_posterior(parallax, distance, sigma_parallax, distance_max) for distance in distance_vals]\n",
    "\n",
    "# Linear posterior is simply the exponent of the log-posterior\n",
    "linear_likelihood_vals = np.exp(log_likelihood_vals)\n",
    "linear_prior_vals = np.exp(log_prior_vals)\n",
    "linear_posterior_vals = np.exp(log_posterior_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e682ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2-panel plot for log-posterior and linear posterior\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot log-posterior (left panel)\n",
    "axs[0].plot(distance_vals, log_likelihood_vals, label=\"Log-Likelihood\", lw=3, c = 'k')\n",
    "axs[0].plot(distance_vals, log_prior_vals, label=\"Log Uni. Prior\", lw=2, ls = 'dotted', c = 'C1')\n",
    "axs[0].plot(distance_vals, log_posterior_vals, label=\"Log-Posterior\", lw=2, ls = 'dashed', c='C1')\n",
    "axs[0].set_xlabel(\"Distance [parsecs]\")\n",
    "axs[0].set_ylabel(\"Log-Posterior\")\n",
    "axs[0].set_title(\"Log-Posterior for Parallax Measurement\")\n",
    "axs[0].set_ylim(-50,10)\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot linear posterior (right panel)\n",
    "axs[1].plot(distance_vals, linear_likelihood_vals/np.max(linear_likelihood_vals), label=\"Linear Likelihood\", lw=3, c = 'k')\n",
    "axs[1].plot(distance_vals, linear_prior_vals/np.max(linear_prior_vals), label=\"Linear Uni. Prior\", lw=2, ls = 'dotted', c = 'C1')\n",
    "axs[1].plot(distance_vals, linear_posterior_vals/np.max(linear_posterior_vals), label=\"Linear Posterior\", lw=2, ls = 'dashed', c='C1')\n",
    "axs[1].set_xlabel(\"Distance [parsecs]\")\n",
    "axs[1].set_ylabel(\"Normalised Probability\")\n",
    "axs[1].set_title(\"Linear Posterior for Parallax Measurement\")\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "\n",
    "\n",
    "# Adjust layout for better viewing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53d25a5",
   "metadata": {},
   "source": [
    "## 5.  Different prior\n",
    "\n",
    "Let's try an exponential prior instead with a specific scale length L:\n",
    "\n",
    "$$\n",
    "P(D_\\varpi) = \\frac{1}{L} \\cdot \\exp{-\\frac{D_\\varpi}{L}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(D_\\varpi=0) = \\frac{1}{L}\n",
    "$$\n",
    "\n",
    "If we go to $D_\\varpi = 5 L$, however, this prior delivers\n",
    "\n",
    "$$\n",
    "P(D_\\varpi = 5L) = \\frac{1}{L} \\cdot \\exp{-5} = 0.0067 \\frac{1}{L}\n",
    "$$\n",
    "\n",
    "The ratio of these two values gives the relative probability\n",
    "$$\n",
    "\\frac{P(D_\\varpi = 5L)}{P(D_\\varpi=0)} = 0.0067\n",
    "$$\n",
    "\n",
    "So at $D_\\varpi = 5L$, the probability has dropped to 0.67% of its initial value at $P(D_\\varpi=0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ce0137",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Previous prior for reference\n",
    "# # Log-Prior function (uniform between 0 and rmax)\n",
    "# def log_prior(distance, distance_max):\n",
    "#     \"\"\"Log-uniform prior for distance (r) truncated between 0 and rmax.\"\"\"\n",
    "#     if distance > 0 and distance < distance_max:\n",
    "#         return -np.log(distance_max)\n",
    "#     else:\n",
    "#         return -np.inf  # log(0) for impossible distances\n",
    "    \n",
    "# Log-Prior function (exponential prior with scale length L)\n",
    "def log_prior2(r, L):\n",
    "    \"\"\"Log-exponential prior for distance with scale length L.\"\"\"\n",
    "    if r > 0:\n",
    "        return -r / L - np.log(L)  # log of exponential distribution\n",
    "    else:\n",
    "        return -np.inf  # log(0) for impossible distances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fdb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's recompute the prior and posterior\n",
    "log_prior2_vals = [log_prior2(distance, L=100) for distance in distance_vals]\n",
    "log_posterior2_vals = np.array(log_likelihood_vals) + np.array(log_prior2_vals)\n",
    "\n",
    "linear_prior2_vals = np.exp(log_prior2_vals)\n",
    "linear_posterior2_vals = np.exp(log_posterior2_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b764350",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create a 2-panel plot for log-posterior and linear posterior\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot log-posterior (left panel)\n",
    "axs[0].plot(distance_vals, log_likelihood_vals, label=\"Log-Likelihood\", lw=3, c = 'k')\n",
    "axs[0].plot(distance_vals, log_prior_vals, label=\"Log Uni. Prior\", lw=2, ls = 'dotted', c = 'C1')\n",
    "axs[0].plot(distance_vals, log_posterior_vals, label=\"Log-Posterior\", lw=2, ls = 'dashed', c='C1')\n",
    "axs[0].plot(distance_vals, log_prior2_vals, label=\"Log Exp. Prior\", lw=2, ls = 'dotted', c = 'C3')\n",
    "axs[0].plot(distance_vals, log_posterior2_vals, label=\"Log-Posterior 2\", lw=2,  ls = 'dashed', c = 'C3')\n",
    "axs[0].set_xlabel(\"Distance [parsecs]\")\n",
    "axs[0].set_ylabel(\"Log-Posterior\")\n",
    "axs[0].set_title(\"Log-Posterior for Parallax Measurement\")\n",
    "axs[0].set_ylim(-50,10)\n",
    "axs[0].legend()\n",
    "axs[0].grid()\n",
    "\n",
    "# Plot linear posterior (right panel)\n",
    "axs[1].plot(distance_vals, linear_likelihood_vals/np.max(linear_likelihood_vals), label=\"Linear Likelihood\", lw=3, c = 'k')\n",
    "axs[1].plot(distance_vals, linear_prior_vals/np.max(linear_prior_vals), label=\"Linear Uni. Prior\", lw=2, ls = 'dotted', c = 'C1')\n",
    "axs[1].plot(distance_vals, linear_posterior_vals/np.max(linear_posterior_vals), label=\"Linear Posterior\", lw=2, ls = 'dashed', c='C1')\n",
    "axs[1].plot(distance_vals, linear_prior2_vals/np.max(linear_prior2_vals), label=\"Linear Exp. Prior\", lw=2, ls = 'dotted', c = 'C3')\n",
    "axs[1].plot(distance_vals, linear_posterior2_vals/np.max(linear_posterior2_vals), label=\"Linear Posterior 2\", lw=2,  ls = 'dashed', c = 'C3')\n",
    "axs[1].set_xlabel(\"Distance [parsecs]\")\n",
    "axs[1].set_ylabel(\"Normalised Probability\")\n",
    "axs[1].set_title(\"Linear Posterior for Parallax Measurement\")\n",
    "axs[1].legend()\n",
    "axs[1].grid()\n",
    "\n",
    "# Adjust layout for better viewing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d150fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "209.59375px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
