{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c5366df",
   "metadata": {},
   "source": [
    "# ANU ASTR4004 2025 - Week 8\n",
    "\n",
    "Author: Dr Sven Buder (sven.buder@anu.edu.au)\n",
    "\n",
    "Based heavily on the Python Data Science Handbook by Jake VanderPlas:  https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html#What-do-the-components-mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44ccb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %matplotlib inline\n",
    "    %config InlineBackend.figure_format='retina'\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import patches\n",
    "\n",
    "# Make the size and fonts larger for this presentation\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['legend.fontsize'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48192e5",
   "metadata": {},
   "source": [
    "## Let's try a different data set: images of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8cbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e8a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load digits dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "np.shape(X), np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8866ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the first few images from the digits dataset\n",
    "fig, axes = plt.subplots(10, 10, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(digits.images[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bff8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f133f52",
   "metadata": {},
   "source": [
    "## Let's try Principal Component Analysis first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81852af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-importing libraries if necessary\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Perform PCA on the digits dataset\n",
    "pca = PCA(2)  # project from 64 to 2 dimensions\n",
    "projected = pca.fit_transform(X_scaled)\n",
    "print(X_scaled.shape)\n",
    "print(projected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca78eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(projected[:, 0], projected[:, 1],\n",
    "            c=digits.target, edgecolor='none', alpha=0.5,\n",
    "            cmap='tab10')\n",
    "plt.xlabel('component 1')\n",
    "plt.ylabel('component 2')\n",
    "plt.colorbar();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eed80e9",
   "metadata": {},
   "source": [
    "Essentially, we have found the optimal stretch and rotation in 64-dimensional space that allows us to see the layout of the digits in two dimensions, and have done this in an unsupervised manner—that is, without reference to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f336e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_pca_components(x, coefficients=None, mean=0, components=None,\n",
    "                        imshape=(8, 8), n_components=8, fontsize=12,\n",
    "                        show_mean=True):\n",
    "    if coefficients is None:\n",
    "        coefficients = x\n",
    "        \n",
    "    if components is None:\n",
    "        components = np.eye(len(coefficients), len(x))\n",
    "        \n",
    "    mean = np.zeros_like(x) + mean\n",
    "        \n",
    "\n",
    "    fig = plt.figure(figsize=(1.2 * (5 + n_components), 1.2 * 2))\n",
    "    g = plt.GridSpec(2, 4 + bool(show_mean) + n_components, hspace=0.3)\n",
    "\n",
    "    def show(i, j, x, title=None):\n",
    "        ax = fig.add_subplot(g[i, j], xticks=[], yticks=[])\n",
    "        ax.imshow(x.reshape(imshape), interpolation='nearest')\n",
    "        if title:\n",
    "            ax.set_title(title, fontsize=fontsize)\n",
    "\n",
    "    show(slice(2), slice(2), x, \"True\")\n",
    "    \n",
    "    approx = mean.copy()\n",
    "    \n",
    "    counter = 2\n",
    "    if show_mean:\n",
    "        show(0, 2, np.zeros_like(x) + mean, r'$\\mu$')\n",
    "        show(1, 2, approx, r'$1 \\cdot \\mu$')\n",
    "        counter += 1\n",
    "\n",
    "    for i in range(n_components):\n",
    "        approx = approx + coefficients[i] * components[i]\n",
    "        show(0, i + counter, components[i], r'$c_{0}$'.format(i + 1))\n",
    "        show(1, i + counter, approx,\n",
    "             r\"${0:.2f} \\cdot c_{1}$\".format(coefficients[i], i + 1))\n",
    "        if show_mean or i > 0:\n",
    "            plt.gca().text(0, 1.05, '$+$', ha='right', va='bottom',\n",
    "                           transform=plt.gca().transAxes, fontsize=fontsize)\n",
    "\n",
    "    show(slice(2), slice(-2, None), approx, \"Approx\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238fa1c",
   "metadata": {},
   "source": [
    "**What do the components mean?**\n",
    "\n",
    "We can go a bit further here, and begin to ask what the reduced dimensions mean. This meaning can be understood in terms of combinations of basis vectors. For example, each image in the training set is defined by a collection of 64 pixel values, which we will call the vector $x$:\n",
    "\n",
    "$$x=[x_1,x_2,x_3,...,x_{64}]$$\n",
    " \n",
    "One way we can think about this is in terms of a pixel basis. That is, to construct the image, we multiply each element of the vector by the pixel it describes, and then add the results together to build the image:\n",
    "\n",
    "$$image(x)=x1⋅(pixel 1)+x2⋅(pixel 2)+x3⋅(pixel 3)⋯x64⋅(pixel 64)$$\n",
    "\n",
    "One way we might imagine reducing the dimension of this data is to zero out all but a few of these basis vectors. For example, if we use only the first eight pixels, we get an eight-dimensional projection of the data, but it is not very reflective of the whole image: we've thrown out nearly 90% of the pixels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cfd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_pca_components(digits.data[10],\n",
    "                          show_mean=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbe0b9",
   "metadata": {},
   "source": [
    "But the pixel-wise representation is not the only choice of basis. We can also use other basis functions, which each contain some pre-defined contribution from each pixel, and write something like\n",
    "\n",
    "$$ image(x)=mean+x1⋅(basis 1)+x2⋅(basis 2)+x3⋅(basis 3) ... $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=8)\n",
    "Xproj = pca.fit_transform(digits.data)\n",
    "\n",
    "fig = plot_pca_components(digits.data[10], Xproj[10],\n",
    "                          pca.mean_, pca.components_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29ce0d",
   "metadata": {},
   "source": [
    "### Why would you want to use PCA?\n",
    "\n",
    "- Simplicity and Speed (no iterative optimization required)\n",
    "- Capturing Maximum Variance (PCA can find dimensions that explain most of the variation of the data)\n",
    "- Deterministic (you will get the same result every time you run the algorithm)\n",
    "- Preserve Global Structure (large distances between clusters or points are well captured in the projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b5122",
   "metadata": {},
   "source": [
    "### Disadvantages of PCA\n",
    "\n",
    "- Linear Relationships (only captures linear relationships between features)\n",
    "- Loss of Local Structure (PCA focuses on variance maximization: points that are close together in the original high-dimensional space might not remain close in the low-dimensional PCA projection)\n",
    "- Explaining Variance vs. Interpretability (principal components themselves may not be easily interpretable; doesn’t necessarily provide an easily interpretable 2D map for complex datasets)\n",
    "- Not Optimized for Clustering (if you want to cluster data, may not separate these clusters effectively)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618ebd1",
   "metadata": {},
   "source": [
    "## t-distributed Stochastic Neighbour Embedding (tSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce305900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=462)\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=462)\n",
    "X_tsne = tsne.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc64c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "# Create the t-SNE plot with images overlayed\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', s=100, alpha=0.6)\n",
    "plt.colorbar()\n",
    "plt.title('t-SNE projection of the Digits dataset with overlayed images')\n",
    "\n",
    "# Function to place images on the scatter plot\n",
    "def imscatter(x, y, images, ax=None, zoom=5):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    for i in range(len(images)):\n",
    "        image = OffsetImage(images[i], zoom=zoom, cmap='gray')\n",
    "        ab = AnnotationBbox(image, (x[i], y[i]), xycoords='data', frameon=False)\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "# Select a few random images to overlay on the plot\n",
    "images_to_overlay = digits.images[:10]  # Choosing the first 10 images for clarity\n",
    "x_positions = X_tsne[:10, 0]  # Corresponding x positions in the t-SNE space\n",
    "y_positions = X_tsne[:10, 1]  # Corresponding y positions in the t-SNE space\n",
    "\n",
    "# Overlay images\n",
    "imscatter(x_positions, y_positions, images_to_overlay)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13fd37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Try different perplexities\n",
    "for perplexity in [5, 30, 50, 100]:\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, random_state=462)\n",
    "    X_tsne = tsne.fit_transform(X_scaled)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='tab10', s=50)\n",
    "    plt.colorbar()\n",
    "    plt.title(f't-SNE with perplexity={perplexity}')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205.987503px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
